{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doronsacha/PythonTestForMivne/blob/main/Low_Collateral_Blockchain_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nv0qzgkl8fa"
      },
      "source": [
        "# Low Collateral Blockchain Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZXKVH5nl8fd",
        "outputId": "4fdcee06-73b5-4423-f5a2-da294a5da73a",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsJ-C0L3l8fe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULM8nHMul8ff"
      },
      "source": [
        "Get the stat file: We will start by obtaining the stat file, which contains relevant data for our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCq-Dwiel8ff"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle('HistoryPoolBorrowersStats.pkl')\n",
        "\n",
        "df = pd.DataFrame.from_dict(data,orient='index')\n",
        "\n",
        "chemin_fichier_csv = 'newStats.csv'\n",
        "\n",
        "df.to_csv(chemin_fichier_csv, index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5CnrkV_l8fg"
      },
      "source": [
        "Add columns and modify the existing file: We will enhance the stat file by adding new columns and modifying existing ones to better suit our analysis requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAwVZbZXl8fg"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file into a dataframe\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "# Remove columns\n",
        "columns_to_remove = ['datesSupplyCollateral', 'datesLoan','datesReimbursement','datesWithdrawCollateral','timeUTCFirstAnyTransactionAccount','borrowerAgeInYears','totalLoans','NumLoans','MeanLoans','totalTimeloans','MeanTimeLoans','totalSupplyCollateral','NumSupplyCollateral','MeanSupplyCollateral','totalReimbursements','NumReimbursements','MeanReimbursements','NumTransactions']  # Specify the names of the columns to remove\n",
        "df = df.drop(columns=columns_to_remove)\n",
        "\n",
        "\n",
        "# Save the modified dataframe to a new CSV file\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C21x-gy0xWs5"
      },
      "source": [
        "This part transfor the dict from date keys to tomestamps keys and also add a new value named ratio for each timestamsp if size debt = 0 then collateralDebtRatio = infinity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGSg8wuuGV--"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "\n",
        "# Define a helper function to convert a date to a timestamp\n",
        "def date_to_timestamp(date_str):\n",
        "    dt_object = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
        "    timestamp = int(time.mktime(dt_object.timetuple()))\n",
        "    return timestamp\n",
        "\n",
        "# Iterate over the Calendar column\n",
        "for i, cell in enumerate(df['Calendar']):\n",
        "    if isinstance(cell, str):\n",
        "        # Replace single quotes with double quotes\n",
        "        cell = cell.replace(\"'\", '\"')\n",
        "        # Load the dictionary\n",
        "        calendar_dict = json.loads(cell)\n",
        "        new_calendar_dict = {}\n",
        "\n",
        "        # Iterate over the days in the calendar_dict\n",
        "        for date_str, day_dict in calendar_dict.items():\n",
        "            # Convert the date to a timestamp and replace it in the dictionary\n",
        "            timestamp = date_to_timestamp(date_str)\n",
        "\n",
        "            # Compute the ratio and insert it into the dictionary\n",
        "            if day_dict['sizeDebtUSD'] != 0:\n",
        "                ratio = day_dict['sizeCollateralUSD'] / day_dict['sizeDebtUSD']\n",
        "            else:\n",
        "                ratio = float('inf')\n",
        "            day_dict['collateralDebtRatio'] = ratio\n",
        "\n",
        "            new_calendar_dict[timestamp] = day_dict\n",
        "\n",
        "        # Replace the row's value in the DataFrame with the updated dictionary\n",
        "        df.at[i, 'Calendar'] = json.dumps(new_calendar_dict)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUeNPet2ysVm"
      },
      "source": [
        "adding most frequent time in the day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sDYb_wSODZd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Define function to convert UNIX timestamp to time of day category\n",
        "def timestamp_to_category(timestamp):\n",
        "    # Convert timestamp to datetime\n",
        "    dt_object = datetime.fromtimestamp(int(float(timestamp)))  # Modify this line\n",
        "    hour = dt_object.hour\n",
        "\n",
        "    # Assign time of day category based on hour\n",
        "    if 6 <= hour < 12:\n",
        "        return \"Morning\"\n",
        "    elif 12 <= hour < 18:\n",
        "        return \"Afternoon\"\n",
        "    elif 18 <= hour < 24:\n",
        "        return \"Evening\"\n",
        "    else:\n",
        "        return \"Night\"\n",
        "\n",
        "# Define function to find the most frequent category in a list\n",
        "def most_frequent_category(lst):\n",
        "    return max(set(lst), key=lst.count) if lst else None\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv('newStats.csv')\n",
        "\n",
        "# Define the timestamp columns to examine\n",
        "timestamp_cols = ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral', 'timeStampFirstAnyTransactionAccount']\n",
        "\n",
        "# Create a new column for the time of day of most transactions\n",
        "df['MostFrequentTransactionTimeOfDay'] = \"\"\n",
        "\n",
        "# Iterate over the DataFrame rows\n",
        "for i, row in df.iterrows():\n",
        "    categories = []\n",
        "    # For each timestamp column, convert the timestamps to categories and add them to the list\n",
        "    for col in timestamp_cols:\n",
        "        if pd.isnull(row[col]):\n",
        "            continue\n",
        "        timestamps = str(row[col]).split()\n",
        "        for timestamp in timestamps:\n",
        "            categories.append(timestamp_to_category(timestamp))\n",
        "    # Determine the most frequent category and assign it to the new column\n",
        "    df.at[i, 'MostFrequentTransactionTimeOfDay'] = most_frequent_category(categories)\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G98wEsVFy9Fp"
      },
      "source": [
        "count the number of days with high ratio(1 but we can change the value if needed) for each user, using the new value in the calendar colomn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HOszi7OX36u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "threshold = 2.2\n",
        "\n",
        "def count_days_with_high_ratio(calendar_str):\n",
        "    # Check if calendar_str is a string\n",
        "    if not isinstance(calendar_str, str):\n",
        "        # Return None (or 0, depending on your needs) if not\n",
        "        return None  # or return 0\n",
        "\n",
        "    # Convert string to dictionary\n",
        "    calendar = json.loads(calendar_str)\n",
        "\n",
        "    count = 0\n",
        "    for day, attributes in calendar.items():\n",
        "        if 'collateralDebtRatio' in attributes and attributes['collateralDebtRatio'] > threshold:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "# Create a new column for the count of days with collateralDebtRatio > 13\n",
        "df['DaysWithHighRatio'] = df['Calendar'].apply(count_days_with_high_ratio)\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-yeA_AA4Pv"
      },
      "source": [
        "if the user paid x percent in the last y month the val is true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6izVyBdscZzp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "x_percent=0.1\n",
        "\n",
        "y_month=9\n",
        "def loan_repaid_x_percent_in_last_y_months(calendar):\n",
        "    # Define the timestamp for 6 months before the day you stopped computing the file\n",
        "    six_months_ago = 1668297600 - y_month*30*24*60*60\n",
        "\n",
        "    # Load the dictionary from the calendar cell\n",
        "    if isinstance(calendar, str):\n",
        "        calendar_dict = json.loads(calendar)\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    # Initialize the total loan and total repayment amounts\n",
        "    total_loan = 0\n",
        "    total_repayment = 0\n",
        "\n",
        "    # Iterate over the days in the calendar_dict\n",
        "    for timestamp, day_dict in calendar_dict.items():\n",
        "        # Convert the timestamp to an integer\n",
        "        timestamp = int(timestamp)\n",
        "\n",
        "        # If the timestamp is within the last 6 months and not before the user's first day\n",
        "        if six_months_ago <= timestamp <= 1668297600:\n",
        "            # Add the loan and repayment amounts for the day to the totals\n",
        "            total_loan += day_dict['sizeDebtUSD']\n",
        "            total_repayment += day_dict['amountPaymentsOnDay']\n",
        "\n",
        "    # If the total loan amount is 0, return False\n",
        "    if total_loan == 0:\n",
        "        return False\n",
        "\n",
        "    # Calculate the repayment percentage\n",
        "    repayment_percentage = total_repayment / total_loan\n",
        "\n",
        "    # If the repayment percentage is at least 66%, return True\n",
        "    if repayment_percentage >= x_percent:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Apply the function to the Calendar column to create a new column\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['Calendar'].apply(loan_repaid_x_percent_in_last_y_months)\n",
        "\n",
        "\n",
        "# Save the updated DataFrame back to csv\n",
        "df.to_csv('newStats.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDxL3wRIl8fg"
      },
      "source": [
        "Create a function to evaluate user behavior: We will develop a function that determines whether a user is classified as good or bad based on their activities on our platform. This function will help us assess user behavior and identify potential risks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipRb7__Hl8fg"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get today's date\n",
        "today = datetime.now()\n",
        "\n",
        "six_months_ago = today - timedelta(days=9*30)  # Assuming each month has 30 days\n",
        "\n",
        "# Convert the dates to timestamps\n",
        "timestamp_today = int(today.timestamp())\n",
        "timestamp_six_months_ago = int(six_months_ago.timestamp())\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_user_behavior(row):\n",
        "    conditions_met = 0\n",
        "\n",
        "\n",
        "    if row['DaysWithHighRatio'] > 60:\n",
        "        conditions_met += 2\n",
        "        if row['LoanRepaidxPercentInLastyMonths']:\n",
        "          conditions_met += 4\n",
        "    if row['timeStampFirstAnyTransactionAccount'] < timestamp_six_months_ago :\n",
        "        conditions_met += 1\n",
        "\n",
        "    if conditions_met==5 or conditions_met == 6 or conditions_met==7 or conditions_met == 3:\n",
        "        return 'Good'\n",
        "    elif conditions_met ==0 :\n",
        "        return 'Bad'\n",
        "    else:\n",
        "        return 'Unknown'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDRE0T7Sl8fh"
      },
      "source": [
        "Run the function for all rows: We will iterate over each row of the stat file and apply the user evaluation function to determine the classification for each user.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYNHcE2Kl8fh"
      },
      "outputs": [],
      "source": [
        "df['user_class'] = df.apply(evaluate_user_behavior, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290gzDGil8fh"
      },
      "source": [
        "Add the new column to the CSV: After evaluating all the users, we will add the newly generated classification column to the CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM234biwl8fi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = df.drop(columns='Calendar')\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('updated_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF7eGzRVl8fi"
      },
      "source": [
        "Run a machine learning model: With the updated CSV file, we will utilize a machine learning model to gain insights and predictions based on the user behavior data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "DBC7ipi8l8fi",
        "outputId": "4896039b-0e32-4a51-9736-a3499190bc7e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-11671d60581f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'error' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Read the data\n",
        "df = pd.read_csv('updated_data.csv')\n",
        "\n",
        "# Drop unnecessary column\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df = df.drop(columns=['Calendar'])\n",
        "# Handle timestamp strings\n",
        "# Handle timestamp strings\n",
        "for col in ['timeStampsSupplyCollateral', 'timeStampsLoans', 'timeStampsReimbursement', 'timeStampsWithdrawCollateral']:\n",
        "    df= df.drop(columns=col)\n",
        "\n",
        "rows_with_nan = df[df.isna().any(axis=1)]\n",
        "\n",
        "df.dropna()\n",
        "# Convert boolean to int\n",
        "df['LoanRepaidxPercentInLastyMonths'] = df['LoanRepaidxPercentInLastyMonths'].astype(int)\n",
        "\n",
        "# Handle categorical columns\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['MostFrequentTransactionTimeOfDay'] = le.fit_transform(df['MostFrequentTransactionTimeOfDay'])\n",
        "df['user_class'] = le.fit_transform(df['user_class'])\n",
        "\n",
        "# Extract features from Calendar dictionary (you need to specify this according to the dictionary's structure)\n",
        "\n",
        "# Normalize numerical columns\n",
        "scaler = StandardScaler()\n",
        "num_cols = ['sizeLoansUSD', 'sizeCollateralUSD', 'sizeReimbursementsUSD', 'numLoansUser', 'maximumDebt', 'atTimeMaximumDebtCollateralProvided', 'ratioCollateralToLoans', 'averageOfDailyCollateralToDebt', 'numTransactionsUser', 'DaysWithHighRatio']\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('user_class', axis=1)\n",
        "y = df['user_class']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Drop rows with NaN values\n",
        "X_train = X_train.dropna()\n",
        "y_train = y_train[X_train.index]\n",
        "\n",
        "# Create a model\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRX8y-Bl8fi"
      },
      "source": [
        "Analyze performance: Finally, we will analyze the performance of our machine learning model and evaluate its effectiveness in predicting user behavior accurately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5UQlICYl8fj"
      },
      "outputs": [],
      "source": [
        "error\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Print the Confusion Matrix and slice it into four pieces for future use\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:\\n', cm)\n",
        "\n",
        "# Calculate Accuracy, Precision, Recall, and F1-Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}\\n')\n",
        "print(f'Classification Report:\\n{report}')\n",
        "\n",
        "# Calculate Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
        "roc_auc = roc_auc_score(y_test, rfc.predict_proba(X_test)[:, 1])\n",
        "print('Area Under ROC Curve: ', roc_auc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}